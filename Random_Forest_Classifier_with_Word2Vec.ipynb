{"cells":[{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint\n\nmyrdd=sc.textFile(\"/FileStore/tables/fine_foods_csv_comma_cleaned.csv\")\n\nmyrdd=myrdd.filter(lambda x: x.split(',')[1]!='userID')\n\ndef punc_remove(x):\n  result=''\n  for i in range(len(x)):\n    if x[i] not in ['.',',',\"'\"]:\n      result=result + x[i]\n    else:\n      result=result + ' '\n  return(result)\n\nmyrdd2=myrdd.map(lambda x:punc_remove(x.split(',')[9]).split(' '))\n\nfrom gensim.models import Word2Vec\n\nmylist=myrdd2.collect()\n\nw2vmodel = Word2Vec(mylist, size=100, window=5, min_count=5, workers=1)\n\ndef avg(x):\n  return sum(x)/len(x)\n\ndef centroid(x):\n  return [avg([x[i][j] for i in range(len(x))]) for j in range(len(x[0]))]\n\ndef check_prefix\n  result=False\n  for i in range(len(x)):\n    result=result or x[:i] in y\n  return result\n\ndef get_features(x):\n  review_string=x.split(',')[9]\n  score=x.split(',')[6]\n  return(LabeledPoint(score,[float(sum([i in ['!'] for i in review_string])),float(sum([check_prefix([\"who\",\"what\",\"where\",\"when\",\"who\",\"why\"]) for i in review_string.split(' ')])),len(review_string.split(' ')),float(sum([check(i,[\"bad\",\"disgusting\",\"terrible\"]) for i in review_string.split(' ')])),float(sum([i in ['?'] for i in review_string])),avg([len(w) for w in review_string.split(' ')])].extend(centroid([modelb[w] for w in review_string.split(' ')]))))\n\ndata=myrdd.map(get_features)\n\nfrom pyspark.mllib.tree import RandomForest\n\n(trainingData, testData) = data.randomSplit([0.7, 0.3])\n\nmodel = RandomForest.trainClassifier(trainingData, categoricalFeaturesInfo={},\n                                     numTrees=3, featureSubsetStrategy=\"auto\",\n                                     impurity='entropy', maxDepth=4, maxBins=32, numClasses=6)\n\npredictions = model.predict(testData.map(lambda x: x.features))\nlabelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n\nerror = labelsAndPredictions.filter(lambda lp:lp[0]!=lp[1]).count()/testData.count()\n\nprint('Test Classification Error = ' + str(error))\nprint('Learned classification forest model:')\nprint(model.toDebugString())\n\ndef my_max(x,y):\n  if x[1]>y[1]:\n    return(x)\n  else:\n    return(y)\n\nmost_common_score=rdd.map(lambda x:[x.split(',')[6],1]).reduceByKey(lambda x,y:x+y).reduce(my_max)[0]\n\nstump_error=testData.filter(lambda lp: lp.label==most_common_score).count()/testData.count()\n\nimprovement=1-stump_error/error\n\nprint('Improvement over one-leaf model:' + str(improvement))\n"],"metadata":{},"outputs":[],"execution_count":1}],"metadata":{"name":"Random Forest Classifier for Score with Word2Vec","notebookId":1171110781417947},"nbformat":4,"nbformat_minor":0}
