{"cells":[{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint\n\nmyrdd=sc.textFile(\"/FileStore/tables/fine_foods_csv_comma_cleaned.csv\")\n\nmyrdd=myrdd.filter(lambda x: x.split(',')[1]!='userID')\n\ndef punc_remove(x):\n  result=''\n  for i in range(len(x)):\n    if x[i] not in ['.',',',\"'\"]:\n      result=result + x[i]\n    else:\n      result=result + ' '\n  return(result)\n\nmyrdd2=myrdd.map(lambda x:punc_remove(x.split(',')[9]).split(' '))\n\nfrom gensim.models import Word2Vec\n\nmylist=myrdd2.collect()\n\nw2vmodel = Word2Vec(mylist, size=100, window=5, min_count=5, workers=1)\n\ndef avg(x):\n  return sum(x)/len(x)\n\ndef centroid(x):\n  return [avg([x[i][j] for i in range(len(x))]) for j in range(len(x[0]))]\n\ndef check_prefix\n  result=False\n  for i in range(len(x)):\n    result=result or x[:i] in y\n  return result\n\ndef get_features(x):\n  review_string=x.split(',')[9]\n  help_count=float(x.split(',')[4])-prefix\n  return(LabeledPoint(help_count,[float(sum([i in ['!'] for i in review_string])),float(sum([check_prefix([\"who\",\"what\",\"where\",\"when\",\"who\",\"why\"]) for i in review_string.split(' ')])),len(review_string.split(' ')),float(sum([check(i,[\"bad\",\"disgusting\",\"terrible\"]) for i in review_string.split(' ')])),float(sum([i in ['?'] for i in review_string])),avg([len(w) for w in review_string.split(' ')])].extend(centroid([modelb[w] for w in review_string.split(' ')])))))\n\ndata=myrdd.map(get_features)\n\nfrom pyspark.mllib.tree import RandomForest\n\n(trainingData, testData) = data.randomSplit([0.7, 0.3])\n\nmodel = RandomForest.trainRegressor(trainingData, categoricalFeaturesInfo={},\n                                     numTrees=3, featureSubsetStrategy=\"auto\",\n                                     impurity='variance', maxDepth=4, maxBins=32)\n\npredictions = model.predict(testData.map(lambda x: x.features)) #x is a LabeledPoint(double label, Vector features) \n\nlabelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions) #get the labels and \"zip\" them together with the predictions in an RDD of length-2 lists\n\ntestMSE = labelsAndPredictions.map(lambda lp: (lp[0] - lp[1]) * (lp[0] - lp[1])).sum() /\\\n    float(testData.count())\nprint('Test Mean Squared Error = ' + str(testMSE))\nprint('Learned regression forest model:')\nprint(model.toDebugString())\n\nhelps=myrdd.map(lambda x:float(x.split(',')[4]))\n\nhelp_avg=helps.sum()/helps.count()\n\nerrs=helps.map(lambda x:(x-help_avg)**2)\n\nvar=errs.sum()/errs.count()\n\nimprovement=1-testMSE/var\n\nprint('Improvement over one-leaf model:' + str(1-testMSE/var))\n"],"metadata":{},"outputs":[],"execution_count":1}],"metadata":{"name":"Random Forest Regressor with Word2Vec","notebookId":1171110781417950},"nbformat":4,"nbformat_minor":0}
